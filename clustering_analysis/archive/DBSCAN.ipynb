{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#time tracking\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PostGres Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(postgresql://patrickmaus@localhost:5432/ais_test)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "database='ais_test'\n",
    "engine = create_engine('postgresql://patrickmaus@localhost:5432/{}'.format(database))\n",
    "\n",
    "engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing at:  2020-03-11 08:59:47.535712\n",
      "Time elapsed: 0:00:00.000424 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tick = datetime.datetime.now()\n",
    "print('Starting processing at: ', tick)\n",
    "\n",
    "tock = datetime.datetime.now()\n",
    "lapse = tock - tick\n",
    "print ('Time elapsed: {} \\n'.format(lapse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Port Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_no</th>\n",
       "      <th>port_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61090</td>\n",
       "      <td>SHAKOTAN</td>\n",
       "      <td>43.866667</td>\n",
       "      <td>146.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61110</td>\n",
       "      <td>MOMBETSU KO</td>\n",
       "      <td>44.350000</td>\n",
       "      <td>143.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5750</td>\n",
       "      <td>CHARLOTTETOWN</td>\n",
       "      <td>46.233333</td>\n",
       "      <td>-63.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61120</td>\n",
       "      <td>ABASHIRI KO</td>\n",
       "      <td>44.016667</td>\n",
       "      <td>144.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61130</td>\n",
       "      <td>NEMURO KO</td>\n",
       "      <td>43.333333</td>\n",
       "      <td>145.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_no      port_name        lat         lon\n",
       "0     61090       SHAKOTAN  43.866667  146.833333\n",
       "1     61110    MOMBETSU KO  44.350000  143.350000\n",
       "2      5750  CHARLOTTETOWN  46.233333  -63.133333\n",
       "3     61120    ABASHIRI KO  44.016667  144.283333\n",
       "4     61130      NEMURO KO  43.333333  145.583333"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ports_full = pd.read_csv('wpi.csv')\n",
    "ports = ports_full[['index_no','port_name','latitude','longitude']]\n",
    "ports = ports.rename(columns={'latitude':'lat','longitude':'lon'})\n",
    "ports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_activity = pd.read_csv('port_activity_sample.csv')\n",
    "port_activity.head()\n",
    "port_activity.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_position = pd.read_csv('ship_position_sample.csv')\n",
    "ship_position.head()\n",
    "ship_position.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.merge(port_activity, ship_position, how='left', on=['mmsi','time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rick = df_full[df_full['mmsi']==538090091]\n",
    "df_rick.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ports = df_full[df_full['port_id'] > 0]\n",
    "df_ports.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len((df_ports['port_id'].unique())))\n",
    "print(len(df_ports))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run DB Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_rick' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-29fce8dcd39f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmin_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_rick\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lon'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_rick' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "eps = .05\n",
    "min_samples = 50\n",
    "\n",
    "X = df_rick[['lon', 'lat']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick = datetime.datetime.now()\n",
    "print('Starting processing with eps={} and min_samples={} at: '.format(str(eps), str(min_samples)), tick)\n",
    "\n",
    "\n",
    "dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "dbscan.fit(X)\n",
    "\n",
    "print('Number of unique labels: ', np.unique(dbscan.labels_))\n",
    "print('Number of  Core Samples:' , len(dbscan.core_sample_indices_))\n",
    "\n",
    "results_dict = {'clust_id': dbscan.labels_,'lat':X[:, 0],'lon':X[:,1]}\n",
    "df_results = pd.DataFrame(results_dict)\n",
    "\n",
    "tock = datetime.datetime.now()\n",
    "lapse = tock - tick\n",
    "print ('Time elapsed: {} \\n'.format(lapse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Center of Each Cluster and compare to nearest Port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 3956  # 6371 Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r\n",
    "\n",
    "def determine_min_distances(df1, name_1, df2, name_2):\n",
    "    min_distances = []\n",
    "    for i in range(len(df1)):\n",
    "        lon1 = df1['lon'].loc[i]\n",
    "        lat1 = df1['lat'].loc[i]\n",
    "        distances = []\n",
    "        for x in range(len(df2)):\n",
    "            lon2 = df2['lon'].loc[x]\n",
    "            lat2 = df2['lat'].loc[x]\n",
    "            dist = haversine(lon1, lat1, lon2, lat2)\n",
    "            distances.append((round(dist,3),df1[name_1].loc[i],df2[name_2].loc[x]))\n",
    "        min_distances.append(min(distances))\n",
    "    return(min_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = determine_min_distances(centers,'clust_id',ports,'port_name')\n",
    "df_dist = pd.DataFrame(dist, columns=['distance from center', 'clust_id', 'nearest_port'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the results from the haversine by mean to get the centerpoint of the cluster\n",
    "centers = df_results.groupby('clust_id').mean().reset_index()\n",
    "# group the same results by count to get the total number of positions\n",
    "counts = df_results.groupby('clust_id').count()\n",
    "# select only one column, in this case I chose lat\n",
    "counts['counts'] = counts['lat']\n",
    "# drop the other columns so count is now just the clust_id and the summed counts\n",
    "counts.drop(['lat','lon'], axis=1, inplace=True)\n",
    "# merge counts and centers\n",
    "centers = pd.merge(centers, counts, how='left', on='clust_id')\n",
    "# merge the full centers file with the results of the haversine equation\n",
    "centers = pd.merge(centers, df_dist, how='left', on='clust_id')\n",
    "centers.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding to Database for QGIS visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Make and test conn and cursor\n",
    "conn = psycopg2.connect(host=\"localhost\",database=database)\n",
    "c = conn.cursor()\n",
    "if c:\n",
    "    print('Connection to {} is good.'.format(database))\n",
    "else:\n",
    "    print('Error connecting.')\n",
    "c.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_table_with_geom(df, name, eps, min_samples):\n",
    "    # add the eps and min_samples value to table name\n",
    "    new_table_name = 'dbscan_results_' + name + '_' + '_' + str(min_samples)\n",
    "    \n",
    "    # drop table if an old one exists\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"\"\"DROP TABLE IF EXISTS {}\"\"\".format(new_table_name))\n",
    "    conn.commit()\n",
    "    c.close()\n",
    "    # make a new table with the df\n",
    "    df.to_sql(new_table_name, engine)\n",
    "    # add a geom column to the new table and populate it from the lat and lon columns\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"\"\"ALTER TABLE {} ADD COLUMN \n",
    "                geom geometry(Point, 4326);\"\"\".format(new_table_name))\n",
    "    conn.commit()\n",
    "    c.execute(\"\"\"UPDATE {} SET \n",
    "                geom = ST_SetSRID(ST_MakePoint(lon, lat), 4326);\"\"\".format(new_table_name))\n",
    "    conn.commit()\n",
    "    c.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_table_with_geom(df_results, 'df_rick', eps, min_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
